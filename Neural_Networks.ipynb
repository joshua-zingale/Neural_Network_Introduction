{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nerual_Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "10kMI4DKEuoT",
        "84-3YNojDi4a"
      ],
      "authorship_tag": "ABX9TyMDfk15cu4MOoFu3FBoH5zV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AgentWombat/Neural_Network_Introduction/blob/main/Nerual_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10kMI4DKEuoT"
      },
      "source": [
        "# What is a Neural Network?\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DW1EtkUCz_E"
      },
      "source": [
        "From pathmind.com:\r\n",
        "\r\n",
        ">\"*Neural networks are a set of algorithms, modeled loosely after the human brain, that are designed to recognize patterns. They interpret sensory data through a kind of machine perception, labeling or clustering raw input. The patterns they recognize are numerical, contained in vectors, into which all real-world data, be it images, sound, text or time series, must be translated.*\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "**But what does that mean?**\r\n",
        "\r\n",
        "The above definition is describing NNs in a very abstract sense. It does not comment on how an NN is implemented. Re-worded, the definition might be \"Neural networks map quantifications of inputs to useful quantifications of outputs.\"\r\n",
        "\r\n",
        "An estute reader might think, \"Wait just a minute. Is that not what a function does?\" And the reader would be correct! An NN is just that: a function.\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "**Functions**\r\n",
        "\r\n",
        "Let us say I want a program that will give me the successor to any natural number. A user will input a word, say \"one\", and recieve the word which is its successor, in this case \"two\". I could try and manually account for each case,\r\n",
        "\r\n",
        "```\r\n",
        "if input == \"one\":\r\n",
        "  return \"two\"\r\n",
        "else if input == \"two\":\r\n",
        "  return \"three\"\r\n",
        "else if...\r\n",
        "```\r\n",
        "\r\n",
        "\r\n",
        "but the inefficiency of this method is obvious with the set of natural numbers having no upper bound.\r\n",
        "\r\n",
        "Instead, I should quantify my inputs, allowing me to utilize the mathematical structure behind the set of words-representing-natural-numbers. While I can not add words together, I can add the integer values of words together. I can use a helper function which takes an english expansion of a natural numbers and converts its related integer:\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "#function to quantify an english word\r\n",
        "def quantify(word):\r\n",
        "  some implementation of english rules\r\n",
        "  ...\r\n",
        "\r\n",
        "#example input\r\n",
        "quantify(\"one-hundred-and-twenty-five\") -> 125\r\n",
        "\r\n",
        "#function to convert back an english word\r\n",
        "def dequantify(word):\r\n",
        "  some implementation of english rules\r\n",
        "  ...\r\n",
        "\r\n",
        "#example input\r\n",
        "quantify(14) -> \"fourteen\"\r\n",
        "\r\n",
        "```\r\n",
        "From there, I can decipher the mathematical relationship between the quantification of an english word for a number and that of its successor.\r\n",
        "\r\n",
        "To determine the pattern of numbers their successors I consider some examples: 1 -> 2, 5 -> 6, 13 -> 14... After some observation, I devise the following function successor(x) = x+1 to map a number to its successor.\r\n",
        "\r\n",
        "Putting the pieces together, and for the purpose of creating a program to return the english word representing the successor of an english word representing a natural number, \r\n",
        "\r\n",
        "\r\n",
        "`output = dequantify(successor(quantify(input)))`.\r\n",
        "\r\n",
        "The important thing is that mathematical functions, like my successor function, can not operate on objects, only on quantifications thereof.\r\n",
        "\r\n",
        "Now, how does this relate to NNs?\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "**Neural Networks**\r\n",
        "\r\n",
        "As said up front, NNs are just functions.  So, like functions, NNs require quantification of inputs and then dequantification of the NN's output to get back an intended output. What differentiates an NN from a function is the method by which the mapping is determined.\r\n",
        "\r\n",
        "Going back to when I was trying to determine the mapping from a number to its successor, I used my mental faculties to observe examples I knew (1 -> 2, 5 -> 6, 13 -> 14...) to devise successor(x) = x + 1. But what if I wanted the computer to determine that for itself?\r\n",
        "\r\n",
        "Just as I analysed examples to determine the mathematic structure of my data, so can a computer achieve this with *machine learning*.\r\n",
        "\r\n",
        ">*A neural network is a function that was determined through the process of machine learning.*\r\n",
        "\r\n",
        "Neural networks are, mathematically, the composition of functions (which is still just a function). Fine tuning these functions with machine learning can result in a desired result. A usefull conceptualisation of Nueral networks is as nodes on a graph (adding to the analogy of neurons in a biological structure).\r\n",
        "\r\n",
        "\r\n",
        "![picture](https://drive.google.com/uc?id=1k3afuA-CzV41jSFHdz8PqnSoF2NGEqae)\r\n",
        "\r\n",
        "Lets say the above structure represents the neural network that will determine the sucessor of a number. It has two nodes (circles) and one connection (the line between the nodes). The first node represents the input to the neural network. For our case, it will hold the value of a natural number 1,2,3,4... The output will be the successor to the input natural number. The connection is where the input will be mapped to the output using some math function.\r\n",
        "\r\n",
        "It could also be drawn like this:\r\n",
        "\r\n",
        "![picture](https://drive.google.com/uc?id=1C4mWPrc4U8rIYwlcTD8llizMuya-c8UB)\r\n",
        "\r\n",
        "Because I already know how to get the successor of a number, I could set the mapping from the input node to the ouput node to f(x) = x + 1. This would lead to the neural network working as intended. The input starts in the input node, gets mapped to the ouput in the connection with the function f(x) = x + 1, and then is returned through the output node.\r\n",
        "\r\n",
        "To use machine learning to determine this function f, I instead define a more general function. I can determine my general function by making an educated guess for the form of my final function. For my successor function, I presume it takes on an affine shape (i.e. f(x) = mx + b). After picking a general form, I initialize my parameters (m and b in this case) to some random values (or perhaps guesses at the correct values). \r\n",
        "\r\n",
        "Let m = 3 and b = 0 => f(x) = 3x + 0\r\n",
        "\r\n",
        "Using this function in my NN leads to the following results:\r\n",
        "\r\n",
        "![picture](https://drive.google.com/uc?id=1v545yBTmpjbzatVEWhXo92SZgagFPAxA)\r\n",
        "\r\n",
        "My NN did not work very well. Aside from the first prediction, every prediction is above what it should be (and it is getting worse and worse). To quantify exactly how bad it performed, I can choose a method of computing the cost of my NN's state. The cost is a measurement of how bad an NN is at predicting what it is intended to predict. It could be calculated in an infinite number of ways. One example is adding up the absolute distances from each predicted point to its true, correct point. As long as the cost is higher for bad performance and lower for good performance, along with other requirements like being differentiable, it will work to some amount of success.\r\n",
        "\r\n",
        "What machine learning will do is, given how the NN performed with certain parameters, is update the parameters such that, ideally, it will perform better next time. The way that parameters are updated changes based on what method is being used and what cost function is in place. It typically involves differentiation of the cost function with respect to each parameter. To learn more about how exactly this works, I reccomend [this video](https://www.youtube.com/watch?v=Ilg3gGewQ5U&t=358s&ab_channel=3Blue1Brown) after finishing this notebook. For now, let us simply assume that there exists a way of determining how to change the parameters such that the next trial of the neural network will likely have better results.\r\n",
        "\r\n",
        "After my computer determines and sets these new parameter values for my NN, it tests itself again, repeating the process of updating parameters utill I tell it to stop. This process of iteratively updating the parameters based on already known data is called \"fitting\" a neural network to or \"Training\" a neural network on data.\r\n",
        "\r\n",
        "Now, lets create and train this neural network to find a numbers successor ourself.\r\n",
        "\r\n",
        "Terminology: Because a neural network *models* some phenomena, a neural network is often called a *model*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84-3YNojDi4a"
      },
      "source": [
        "# Creating a 'Successor' Neural Network\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SptKOJLhDsJV"
      },
      "source": [
        "# IMPORTS\r\n",
        "# We will be using the Keras Tensorflow API to create and train a neural network.\r\n",
        "\r\n",
        "# First, import the required libraries for creating our \r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras import Input\r\n",
        "\r\n",
        "# This import is only for making graphs to visualize our model.\r\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGLgjCH3EvBK"
      },
      "source": [
        "# CREATE DATA\r\n",
        "# In order for our NN to learn how to predict a number's sucessor, we need to\r\n",
        "# provide some example pairs of numbers and their successors.\r\n",
        "\r\n",
        "x = [i for i in range(1,10001)] # an array of numbers from 1 to 10000 (inclusive)\r\n",
        "y = [i + 1 for i in x] # for each i in [1,10000], y[i] = x[i] + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyxkmMI-FWb0"
      },
      "source": [
        "# CREATE MODEL'S GRAPH/ARCHITECTURE\r\n",
        "# Remember that the model we are creating has two nodes: input and output.\r\n",
        "# The two nodes are also aranged in a sequential fassion--one after the other.\r\n",
        "\r\n",
        "# So, we start by making a \"Sequential\" model\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# The model should have two nodes with one connection between the nodes.\r\n",
        "# In other terms, our model will have two layers with one node per layer\r\n",
        "# and all values in the first layer being passed into the all nodes in the second.\r\n",
        "\r\n",
        "# The input of our model is one value, so it has the shape (1,) which means that\r\n",
        "# it will take 1 dimensional vectors.\r\n",
        "# Setting the shape to (k,) is the same as saying that the model will have k\r\n",
        "# input nodes \r\n",
        "model.add(Input(shape = (1,)))\r\n",
        "\r\n",
        "# To get the behavior we want, we use a Dense layer with one node.\r\n",
        "# A Dense node uses an affine function (f(x) = mx + b) when recieving a value\r\n",
        "# from another node (in this case our input)\r\n",
        "# The argument 1 specifies how many nodes are in the layer.\r\n",
        "model.add(Dense(1))\r\n",
        "\r\n",
        "# Because this is our last layer, it will automatically be the output\r\n",
        "\r\n",
        "# Lastly, we must compile the model to determine how it will learn.\r\n",
        "# We will use \"mean squared error\" as a loss function (part of how cost\r\n",
        "# is calculated) and the \"adam\" optimizer.\r\n",
        "model.compile(loss='mse', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5K1piD5J16g",
        "outputId": "de937898-d27f-4866-c170-86a1cfe568ea"
      },
      "source": [
        "# TRAIN OUR MODEL\r\n",
        "# We will train our model based on the imput output pairs we created earlier.\r\n",
        "# Epochs are a measure of how many times the model will consider each data pair.\r\n",
        "# Epochs = 1 means our model will be \"fit\" to the data once.\r\n",
        "model.fit(x,y, epochs = 1)\r\n",
        "\r\n",
        "print(model.weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 917us/step - loss: 78917201.7197\n",
            "[<tf.Variable 'dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[-0.319684]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.29861477], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "VPBc_xdyPSWV",
        "outputId": "fa7b0978-aa71-4b15-9eed-5bc5a6fa90ef"
      },
      "source": [
        "# Graph model against real data to gauge its performance\r\n",
        "\r\n",
        "plt.plot(x,y, label = 'Actual')\r\n",
        "plt.plot(x,model.predict(x), label = 'Predicted')\r\n",
        "plt.xlabel('Numbers')\r\n",
        "plt.ylabel('Successor')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82kR16QBL1M7",
        "outputId": "18fd49e7-70d6-4fef-d519-9eeef960eb0a"
      },
      "source": [
        "# TEST MODEL\r\n",
        "\r\n",
        "# The model predict continuous values; however, we want integers.\r\n",
        "print(\"Continuous values:\\n\", model.predict([1,2,3,4,5,6,7,8,9]))\r\n",
        "\r\n",
        "print(\"\\n\\n\\nIntegers:\\n\",[1,2,3,4,5,6,7,8,9])\r\n",
        "#So, we round each prediction to its closest integer.\r\n",
        "print(\"\\nInteger Successors:\\n\",[round(i[0]) for i in (model.predict([1,2,3,4,5,6,7,8,9]))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Continuous values:\n",
            " [[-0.02106923]\n",
            " [-0.34075323]\n",
            " [-0.6604372 ]\n",
            " [-0.98012125]\n",
            " [-1.2998053 ]\n",
            " [-1.6194892 ]\n",
            " [-1.9391732 ]\n",
            " [-2.2588573 ]\n",
            " [-2.5785413 ]]\n",
            "\n",
            "\n",
            "\n",
            "Integers:\n",
            " [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "\n",
            "Integer Successors:\n",
            " [0, 0, -1, -1, -1, -2, -2, -2, -3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMVNpdMhQEKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "167b7887-e2aa-4052-970c-2eb76c9422b7"
      },
      "source": [
        "# The model needs more training as it does not accurately predict a\r\n",
        "# numbers successor\r\n",
        "\r\n",
        "model.fit(x,y, epochs = 100)\r\n",
        "\r\n",
        "print(model.weights)\r\n",
        "\r\n",
        "# NOTE: Usually, a the number of epochs is much smaller than 100 (making it that\r\n",
        "# high might actually hurt your models performance). Because we are fitting our\r\n",
        "# model to an elementry math function and there is a large range of outputs,\r\n",
        "# its behavior is atypical"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "313/313 [==============================] - 0s 913us/step - loss: 46979880.0000\n",
            "Epoch 2/100\n",
            "313/313 [==============================] - 0s 871us/step - loss: 29206564.0000\n",
            "Epoch 3/100\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 17050720.0000\n",
            "Epoch 4/100\n",
            "313/313 [==============================] - 0s 895us/step - loss: 9218452.0000\n",
            "Epoch 5/100\n",
            "313/313 [==============================] - 0s 894us/step - loss: 4535898.0000\n",
            "Epoch 6/100\n",
            "313/313 [==============================] - 0s 874us/step - loss: 1985601.1250\n",
            "Epoch 7/100\n",
            "313/313 [==============================] - 0s 920us/step - loss: 755079.9375\n",
            "Epoch 8/100\n",
            "313/313 [==============================] - 0s 861us/step - loss: 242130.3281\n",
            "Epoch 9/100\n",
            "313/313 [==============================] - 0s 842us/step - loss: 63357.7539\n",
            "Epoch 10/100\n",
            "313/313 [==============================] - 0s 911us/step - loss: 13069.5156\n",
            "Epoch 11/100\n",
            "313/313 [==============================] - 0s 876us/step - loss: 2040.1610\n",
            "Epoch 12/100\n",
            "313/313 [==============================] - 0s 931us/step - loss: 229.5537\n",
            "Epoch 13/100\n",
            "313/313 [==============================] - 0s 863us/step - loss: 17.5969\n",
            "Epoch 14/100\n",
            "313/313 [==============================] - 0s 852us/step - loss: 0.9481\n",
            "Epoch 15/100\n",
            "313/313 [==============================] - 0s 875us/step - loss: 0.1226\n",
            "Epoch 16/100\n",
            "313/313 [==============================] - 0s 881us/step - loss: 0.0988\n",
            "Epoch 17/100\n",
            "313/313 [==============================] - 0s 885us/step - loss: 0.0984\n",
            "Epoch 18/100\n",
            "313/313 [==============================] - 0s 797us/step - loss: 0.0983\n",
            "Epoch 19/100\n",
            "313/313 [==============================] - 0s 947us/step - loss: 0.0982\n",
            "Epoch 20/100\n",
            "313/313 [==============================] - 0s 864us/step - loss: 0.0982\n",
            "Epoch 21/100\n",
            "313/313 [==============================] - 0s 942us/step - loss: 0.0981\n",
            "Epoch 22/100\n",
            "313/313 [==============================] - 0s 834us/step - loss: 0.0981\n",
            "Epoch 23/100\n",
            "313/313 [==============================] - 0s 785us/step - loss: 0.0981\n",
            "Epoch 24/100\n",
            "313/313 [==============================] - 0s 881us/step - loss: 0.0980\n",
            "Epoch 25/100\n",
            "313/313 [==============================] - 0s 897us/step - loss: 0.0979\n",
            "Epoch 26/100\n",
            "313/313 [==============================] - 0s 840us/step - loss: 0.0978\n",
            "Epoch 27/100\n",
            "313/313 [==============================] - 0s 797us/step - loss: 0.0977\n",
            "Epoch 28/100\n",
            "313/313 [==============================] - 0s 807us/step - loss: 0.0976\n",
            "Epoch 29/100\n",
            "313/313 [==============================] - 0s 906us/step - loss: 0.0975\n",
            "Epoch 30/100\n",
            "313/313 [==============================] - 0s 849us/step - loss: 0.0973\n",
            "Epoch 31/100\n",
            "313/313 [==============================] - 0s 922us/step - loss: 0.0971\n",
            "Epoch 32/100\n",
            "313/313 [==============================] - 0s 907us/step - loss: 0.0968\n",
            "Epoch 33/100\n",
            "313/313 [==============================] - 0s 848us/step - loss: 0.0965\n",
            "Epoch 34/100\n",
            "313/313 [==============================] - 0s 872us/step - loss: 0.0962\n",
            "Epoch 35/100\n",
            "313/313 [==============================] - 0s 881us/step - loss: 0.0958\n",
            "Epoch 36/100\n",
            "313/313 [==============================] - 0s 808us/step - loss: 0.0954\n",
            "Epoch 37/100\n",
            "313/313 [==============================] - 0s 848us/step - loss: 0.0949\n",
            "Epoch 38/100\n",
            "313/313 [==============================] - 0s 859us/step - loss: 0.0944\n",
            "Epoch 39/100\n",
            "313/313 [==============================] - 0s 941us/step - loss: 0.0936\n",
            "Epoch 40/100\n",
            "313/313 [==============================] - 0s 913us/step - loss: 0.0928\n",
            "Epoch 41/100\n",
            "313/313 [==============================] - 0s 868us/step - loss: 0.0919\n",
            "Epoch 42/100\n",
            "313/313 [==============================] - 0s 813us/step - loss: 0.0909\n",
            "Epoch 43/100\n",
            "313/313 [==============================] - 0s 899us/step - loss: 0.0896\n",
            "Epoch 44/100\n",
            "313/313 [==============================] - 0s 865us/step - loss: 0.0881\n",
            "Epoch 45/100\n",
            "313/313 [==============================] - 0s 909us/step - loss: 0.0865\n",
            "Epoch 46/100\n",
            "313/313 [==============================] - 0s 848us/step - loss: 0.0846\n",
            "Epoch 47/100\n",
            "313/313 [==============================] - 0s 798us/step - loss: 0.0823\n",
            "Epoch 48/100\n",
            "313/313 [==============================] - 0s 918us/step - loss: 0.0799\n",
            "Epoch 49/100\n",
            "313/313 [==============================] - 0s 867us/step - loss: 0.0770\n",
            "Epoch 50/100\n",
            "313/313 [==============================] - 0s 938us/step - loss: 0.0742\n",
            "Epoch 51/100\n",
            "313/313 [==============================] - 0s 844us/step - loss: 0.0706\n",
            "Epoch 52/100\n",
            "313/313 [==============================] - 0s 969us/step - loss: 0.0670\n",
            "Epoch 53/100\n",
            "313/313 [==============================] - 0s 871us/step - loss: 0.0624\n",
            "Epoch 54/100\n",
            "313/313 [==============================] - 0s 875us/step - loss: 0.0580\n",
            "Epoch 55/100\n",
            "313/313 [==============================] - 0s 879us/step - loss: 0.0529\n",
            "Epoch 56/100\n",
            "313/313 [==============================] - 0s 856us/step - loss: 0.0478\n",
            "Epoch 57/100\n",
            "313/313 [==============================] - 0s 946us/step - loss: 0.0424\n",
            "Epoch 58/100\n",
            "313/313 [==============================] - 0s 956us/step - loss: 0.0367\n",
            "Epoch 59/100\n",
            "313/313 [==============================] - 0s 909us/step - loss: 0.0319\n",
            "Epoch 60/100\n",
            "313/313 [==============================] - 0s 891us/step - loss: 0.0265\n",
            "Epoch 61/100\n",
            "313/313 [==============================] - 0s 836us/step - loss: 0.0206\n",
            "Epoch 62/100\n",
            "313/313 [==============================] - 0s 892us/step - loss: 0.0162\n",
            "Epoch 63/100\n",
            "313/313 [==============================] - 0s 922us/step - loss: 0.0119\n",
            "Epoch 64/100\n",
            "313/313 [==============================] - 0s 802us/step - loss: 0.0084\n",
            "Epoch 65/100\n",
            "313/313 [==============================] - 0s 876us/step - loss: 0.0056\n",
            "Epoch 66/100\n",
            "313/313 [==============================] - 0s 842us/step - loss: 0.0037\n",
            "Epoch 67/100\n",
            "313/313 [==============================] - 0s 928us/step - loss: 0.0022\n",
            "Epoch 68/100\n",
            "313/313 [==============================] - 0s 882us/step - loss: 0.0109\n",
            "Epoch 69/100\n",
            "313/313 [==============================] - 0s 873us/step - loss: 0.0036\n",
            "Epoch 70/100\n",
            "313/313 [==============================] - 0s 897us/step - loss: 0.0095\n",
            "Epoch 71/100\n",
            "313/313 [==============================] - 0s 929us/step - loss: 0.0658\n",
            "Epoch 72/100\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.1306\n",
            "Epoch 73/100\n",
            "313/313 [==============================] - 0s 854us/step - loss: 6.0090e-04\n",
            "Epoch 74/100\n",
            "313/313 [==============================] - 0s 784us/step - loss: 0.0013\n",
            "Epoch 75/100\n",
            "313/313 [==============================] - 0s 937us/step - loss: 0.0443\n",
            "Epoch 76/100\n",
            "313/313 [==============================] - 0s 935us/step - loss: 0.0022\n",
            "Epoch 77/100\n",
            "313/313 [==============================] - 0s 917us/step - loss: 0.1329\n",
            "Epoch 78/100\n",
            "313/313 [==============================] - 0s 889us/step - loss: 1.3276e-04\n",
            "Epoch 79/100\n",
            "313/313 [==============================] - 0s 927us/step - loss: 0.0355\n",
            "Epoch 80/100\n",
            "313/313 [==============================] - 0s 844us/step - loss: 0.2064\n",
            "Epoch 81/100\n",
            "313/313 [==============================] - 0s 904us/step - loss: 1.7325e-06\n",
            "Epoch 82/100\n",
            "313/313 [==============================] - 0s 909us/step - loss: 8.2996e-06\n",
            "Epoch 83/100\n",
            "313/313 [==============================] - 0s 847us/step - loss: 0.0919\n",
            "Epoch 84/100\n",
            "313/313 [==============================] - 0s 828us/step - loss: 0.0071\n",
            "Epoch 85/100\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 3.6816e-04\n",
            "Epoch 86/100\n",
            "313/313 [==============================] - 0s 967us/step - loss: 0.0707\n",
            "Epoch 87/100\n",
            "313/313 [==============================] - 0s 897us/step - loss: 0.0099\n",
            "Epoch 88/100\n",
            "313/313 [==============================] - 0s 950us/step - loss: 0.1802\n",
            "Epoch 89/100\n",
            "313/313 [==============================] - 0s 920us/step - loss: 2.1336e-06\n",
            "Epoch 90/100\n",
            "313/313 [==============================] - 0s 966us/step - loss: 0.1998\n",
            "Epoch 91/100\n",
            "313/313 [==============================] - 0s 934us/step - loss: 0.0396\n",
            "Epoch 92/100\n",
            "313/313 [==============================] - 0s 916us/step - loss: 3.2725e-06\n",
            "Epoch 93/100\n",
            "313/313 [==============================] - 0s 958us/step - loss: 2.3509e-06\n",
            "Epoch 94/100\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 95/100\n",
            "313/313 [==============================] - 0s 919us/step - loss: 0.2944\n",
            "Epoch 96/100\n",
            "313/313 [==============================] - 0s 906us/step - loss: 4.4024e-06\n",
            "Epoch 97/100\n",
            "313/313 [==============================] - 0s 910us/step - loss: 1.3595e-05\n",
            "Epoch 98/100\n",
            "313/313 [==============================] - 0s 954us/step - loss: 3.3895e-06\n",
            "Epoch 99/100\n",
            "313/313 [==============================] - 0s 935us/step - loss: 6.8086e-05\n",
            "Epoch 100/100\n",
            "313/313 [==============================] - 0s 853us/step - loss: 0.2389\n",
            "[<tf.Variable 'dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[0.9999996]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([1.002709], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "08V4kALbRMYz",
        "outputId": "b443b52d-eb4c-49a4-b721-88462e12223f"
      },
      "source": [
        "# Graph model against real data to gauge its performance\r\n",
        "\r\n",
        "plt.plot(x,y, label = 'Actual')\r\n",
        "plt.plot(x,model.predict(x), label = 'Predicted')\r\n",
        "plt.xlabel('Numbers')\r\n",
        "plt.ylabel('Successor')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16YfLr8KREp1",
        "outputId": "f57f65ba-b547-4db3-dee2-860740c61800"
      },
      "source": [
        "# TEST MODEL\r\n",
        "\r\n",
        "# The model predict continuous values; however, we want integers.\r\n",
        "print(\"Continuous values:\\n\", model.predict([1,2,3,4,5,6,7,8,9,100]))\r\n",
        "\r\n",
        "print(\"\\n\\n\\nIntegers:\\n\",[1,2,3,4,5,6,7,8,9,100])\r\n",
        "#So, we round each prediction to its closest integer.\r\n",
        "print(\"\\nInteger Successors:\\n\",[round(i[0]) for i in (model.predict([1,2,3,4,5,6,7,8,9,100]))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Continuous values:\n",
            " [[  2.0027087]\n",
            " [  3.0027082]\n",
            " [  4.002708 ]\n",
            " [  5.0027075]\n",
            " [  6.002707 ]\n",
            " [  7.0027065]\n",
            " [  8.002707 ]\n",
            " [  9.002706 ]\n",
            " [ 10.002706 ]\n",
            " [101.00267  ]]\n",
            "\n",
            "\n",
            "\n",
            "Integers:\n",
            " [1, 2, 3, 4, 5, 6, 7, 8, 9, 100]\n",
            "\n",
            "Integer Successors:\n",
            " [2, 3, 4, 5, 6, 7, 8, 9, 10, 101]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY1bK26GRXUj"
      },
      "source": [
        "# That is all!\r\n",
        "# We have trained a neural network to know what the successor to an integer is."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMgpVKuyRoZw"
      },
      "source": [
        "# A More Complex Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHqq-aUSR6fA"
      },
      "source": [
        "The model we described and then created was very basic. Of course a computer can learn to approximate a simple algebraic function.\r\n",
        "\r\n",
        "How about we train one to classify images?\r\n",
        "\r\n",
        "---\r\n",
        "**Classification**\r\n",
        "\r\n",
        ">*Classification is where a neural network takes in some data, whatever it may be, and assigns it to a one or more classes.* \r\n",
        "\r\n",
        "An example might be a neural network in a self-driving car to regognize what is extant in front of a car. The car would take images and send them to the NN; the NN would then classify/label the images (e.g. NN(img) -> Person & Car & Tree).\r\n",
        "\r\n",
        "Before we get into crafting a model, let us first advance our understanding of neural network architecture.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "**A Second look at Neural Networks**\r\n",
        "\r\n",
        "For our last model, the one to determind a number's successor, it had only two nodes and one connection between them. That was a very simple example. \r\n",
        "\r\n",
        "Typically, there will be more than one node in a layer.\r\n",
        "\r\n",
        "![picture](https://drive.google.com/uc?id=1YggPrM5IQzee_YLMYp8098i2LS0Lk60E)\r\n",
        "\r\n",
        "Before, the output was the result of the input * m + b. Now, the output is equal to the sum of the each input multiplied by an associated weight (w), all added to some bias (b). \r\n",
        "\r\n",
        "Lets say both weights equal 2 and the bias equals 10. If [3,5] was input to the neural network, I_0 becomes 3 and I_1 becomes 5. Consequently, the output equals 2 * 3 + 2 * 5 + 10 = 26.\r\n",
        "\r\n",
        "The above NN can only learn linear functions. That means that each input will be mapped proportionately to an output.\r\n",
        "\r\n",
        "To fix this problem, NNs almost alwas use non-linear activation functions.\r\n",
        "\r\n",
        "\r\n",
        "![picture](https://drive.google.com/uc?id=1spKSSxw2VJ3NvL2ycW_XYD3kJt0D2W2O)\r\n",
        "\r\n",
        "An activation function takes the value of a node and modifies it. One activation function could be a(x) = 1/x. Implementing an activation function to the input layer, this would make the ouput instead equal w_0 * a(I_0) + w_1 * a(I_1) + b. a(I_0) is called I_0's *activation*. Typically, activation nodes, the small ones in my diagram, are not drawn but instead assumed.\r\n",
        "\r\n",
        "By adding more nodes and more layers, assuming a non-linear activation function is implemented, neural networks can approximate any math function.\r\n",
        "\r\n",
        "All layers of a neural network aside from the input and output layers are labeled as hidden layers because a user of a trained model does not need to know anything about the hidden layers.\r\n",
        "\r\n",
        "![picture](https://drive.google.com/uc?id=1OY438avjFrEXZGTPBfVOaNT5J7ah0Rdf)\r\n",
        "\r\n",
        "All layers behave the same. The value of each node in the hidden layer is calculated the same way the output was calculated before. Each node in layer N + 1 is (w_i*(a_i)) + b. Where a_i is the i-th activation of layer N (i.e. (a([N-th layer node]_i))).\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "**Classification**\r\n",
        "\r\n",
        "I want to create a neural network to identify what number is contained in an image file like the one below.\r\n",
        "\r\n",
        "![picture](https://drive.google.com/uc?id=1E3TMwJsOAX_1rH50eVfXNS8tsJ8SriVm)\r\n",
        "\r\n",
        "The goal is that by training a neural network on a large number of pre-labeled examples, it can learn how to identify hand writen digits without the digits being labeled. This process is similar to how a child might learn the numeral of any given digit. A child is not indoctrinated with a mathematical formula for parsing image data such that he or she can see the numeral for '2' and then identify it as such; a child learns the numeral for '2' by seeing a large amount of examples and being told \"this is a two.\"\r\n",
        "\r\n",
        "For the learning process, I will feed an image to my model and then compare its guess to what the correct label is, chastising the model if it guesses wrong.\r\n",
        "\r\n",
        "The first step is to quantify my input. Just as math can not directly be done on \"one\" and \"two\", neither can math be done on a PNG file without first quantifying. Because the images I will be using are 28x28 and in greyscale, meaning each pixel is defined by a brightness on [0-255], an image will be represented by a two dimensional array with dimensions 28x28 and each index holding a value between 0 and 255.\r\n",
        "\r\n",
        "```\r\n",
        "# 2D array with 28 rows and 28 columns\r\n",
        "two = [[0,0, 0, 0... 0,0],\r\n",
        "       [0,0,103,82.. 0,0],\r\n",
        "       .................. \r\n",
        "       [0,12,57,0... 0,0],\r\n",
        "       [0,0,103,82.. 0,0]]\r\n",
        "```\r\n",
        "\r\n",
        "For the models covered here, the input is always 1D array, so I will flatten it such that each pixel becomes an index in one big vector.\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "# 1D array with 28^2 = 784 indices\r\n",
        "two = [0,0,0,0,0,0... 38,58,0... 242,0,0,0]\r\n",
        "```\r\n",
        "\r\n",
        "For purposes of imporving the models ability to train, inputs are typically normalized to all be withing the range of 0-1, -1 to 1, or some other small range. To do this for my data, I can simply divide each number by 255, leading to every value ranging between 0 and 1.\r\n",
        "\r\n",
        "With the images now quantified, mathematic relationships can be detected through machine learning. The model might deduce that when pixel 90 is very bright, it is likely that '7' was drawn.\r\n",
        "\r\n",
        "To have my model guess a number based on the input, I could have it oneput a single number. There are problems with this. There are only 10 valid guesses, [0, 9], and if the model where to guess a single number, it has an near infinite number of possible outputs. Additionaly, if the correct answer was '3' and the model guessed wrong, it would be punished more harshely for outputing '8' than '1'. This does not make sense as guessing a wrong number is no more correct if it is additively close. \r\n",
        "\r\n",
        "As an alternative, and what is almost always done is cases such as these, I will set my model to have ten output nodes, where each node represents a number on [0,9]. Whichever output node contains the largest value can be considered to be the model's guess.\r\n",
        "\r\n",
        "Having ten output nodes means that the model expects to see vectors with 10 elements as example labels/outputs. Numbers will be encoded such that all values in a vector will be '0' except for the index corresponding to the number.This type is encoding is called *one hot encoding*.\r\n",
        "\r\n",
        "```\r\n",
        "# How 0 is encoded\r\n",
        "[1,0,0,0,0,0,0,0,0,0]\r\n",
        "\r\n",
        "# How 6 is encoded\r\n",
        "[0,0,0,0,0,0,1,0,0,0]\r\n",
        "```\r\n",
        "\r\n",
        "For the model to gauge how well it guessed, it will compare its output to the correct output. For this model, it only really makes sinse for it to have values between 0 and 1 in its output. To ensure it has this, I will use an activation function called \"softmax\" which not only ensures all outputs are between 0 and 1, but also that all outputs add up to 1. All outputs adding to one has the added benefit that each number in the ouput vector can be interpreted as a probability (all probabilities should add to be 1).\r\n",
        "\r\n",
        "```\r\n",
        "# An image with '1' drawn on it is input\r\n",
        "\r\n",
        "# What the model predicts\r\n",
        "[0.1,0.2,0,0,0.3,0.1,0.1,0,0.1,0.1]\r\n",
        "\r\n",
        "# What the correct output is\r\n",
        "[0,1,0,0,0,0,0,0,0,0]\r\n",
        "\r\n",
        "# The the machine learning process compares the two vectors\r\n",
        "\r\n",
        "[0.1,0.2,0,0,0.3,0.1,0.1,0,0.1,0.1]\r\n",
        "[0,1,0,0,0,0,0,0,0,0]\r\n",
        "\r\n",
        "# It sees that indices 0,4,5,6,8,9 should have been lower and\r\n",
        "# index 1 should have been higher.\r\n",
        "# Through backpropagation, parameters are changed such that the model should\r\n",
        "# guess better next time\r\n",
        "```\r\n",
        "\r\n",
        "After my model has learned from thousands of examples, I can evaluate how accurately it labels numbers. I might be tempted to evaluate by seeing how well it labels images from the data on which I trained the model, but that would be cheating. The goal of creating a neural network is not to correctly identify the data on which I trained it, but for the NN to correctly identify never-before-seen images. When evaluating the model on the data which trained it, the model could have simple \"memorized\" the specific examples (in the event that this occurs, the model is said to have *overfit* to the data).\r\n",
        "\r\n",
        "So, to evaluate my model, I test in on a data set it has never seen before.\r\n",
        "\r\n",
        "That is the basics of classification. Let us now code the very classification model I have described above.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeTUBFzBjo2R"
      },
      "source": [
        "# Creating a Classification Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHAppWoPjwNy"
      },
      "source": [
        "# IMPORTS\r\n",
        "# We will be using the Keras Tensorflow API to create and train a neural network.\r\n",
        "\r\n",
        "# First, import the required libraries for creating our \r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras import Input\r\n",
        "from tensorflow.keras.datasets import mnist\r\n",
        "\r\n",
        "# For easier handling of arrays, import numpy\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# This import is only for displaying graphics\r\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTp634TOkA-F"
      },
      "source": [
        "# LOAD DATA\r\n",
        "# Load mnist data set. It contains 60,000 training and 10,000 testing examples\r\n",
        "# of labeled hand drawn digits represented in 28*28 arrays.\r\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n",
        "\r\n",
        "# Normalize data to all be in the range of 0 to 1\r\n",
        "x_train = x_train/255.0\r\n",
        "x_test = x_test/255.0\r\n",
        "\r\n",
        "# We will later flatten the data to be a 1D arrray."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OmHG7xglMt1"
      },
      "source": [
        "# ONE HOT ENCODE\r\n",
        "# Define function to one hot encode labels\r\n",
        "def to_one_hot(array):\r\n",
        "  new_array = np.zeros(shape = (array.shape[0], 10))\r\n",
        "\r\n",
        "  for i, num in enumerate(array):\r\n",
        "    one_hot_vector = np.zeros(10)\r\n",
        "    one_hot_vector[num] = 1\r\n",
        "    new_array[i] = one_hot_vector\r\n",
        "\r\n",
        "  return new_array\r\n",
        "\r\n",
        "# One hot encode labels\r\n",
        "# 1 -> [0,1,0,0,0,0,0,0,0,0], 4 -> [0,0,0,0,1,0,0,0,0,0]\r\n",
        "y_train = to_one_hot(y_train)\r\n",
        "\r\n",
        "y_test = to_one_hot(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtYm3PnhmhAo"
      },
      "source": [
        "# See first training example and its label \r\n",
        "plt.imshow(x_train[0], cmap='gray')\r\n",
        "print(y_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsFazkrxnJl1"
      },
      "source": [
        "# DEFINE MODEL ARCHITECTURE\r\n",
        "# Just as in the previous neural network, a sequential model will suffice for \r\n",
        "# our purposes\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# The first layer is the input layer\r\n",
        "# Remember, we will be feedint the model flattened 28x28 arras, which are\r\n",
        "# 1D 28^2 = 784 element arrays.\r\n",
        "# Hence, we need 784 input nodes.\r\n",
        "model.add(Input(shape = (784,)))\r\n",
        "\r\n",
        "# Now we define our hidden layers.\r\n",
        "# There is no obviously 'correct' number of nodes per layer or even\r\n",
        "# number of layers to use.\r\n",
        "# I arbitrarily chose two hidden layers with 16 nodes in each\r\n",
        "# For the activation function, we need to use something non-linear.\r\n",
        "# The state-of-the-art default choice for an activation function is\r\n",
        "# rectified linear (or 'relu')\r\n",
        "# Sidenote: relu(x) = max(0,x)\r\n",
        "# 'sigmoid' or 'tanh' are other common options\r\n",
        "\r\n",
        "# When passing the activation argument into a layer, think of it as\r\n",
        "# creating an \"activation layer\" between the current layer and the next\r\n",
        "\r\n",
        "model.add(Dense(16, activation = 'relu'))\r\n",
        "\r\n",
        "model.add(Dense(16, activation = 'relu'))\r\n",
        "\r\n",
        "# To classify an image, we will create 10 output nodes with a 'softmax'\r\n",
        "# activation function.\r\n",
        "# The softmax activation function ensures that all outputs will be on [0,1]\r\n",
        "# and that the ouputs sum to 1\r\n",
        "\r\n",
        "model.add(Dense(10, activation='softmax'))\r\n",
        "\r\n",
        "# Now we compile the model to define how it learns by setting a loss function\r\n",
        "# and optimizer\r\n",
        "# For classification problems, we want to use 'categorical_crossentropy'\r\n",
        "# It is used as a loss function when there are more than two classes being\r\n",
        "# predicted.\r\n",
        "\r\n",
        "# 'metrics' defines what metrics are displayed while training and what metrics\r\n",
        "# will be stored in the even that someone wishes to analise the models history\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer ='adam',\r\n",
        "              metrics =['accuracy'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioMRTSJxq0cZ",
        "outputId": "cf068c18-1cff-4ba7-f863-2598cfba0177"
      },
      "source": [
        "# TRAIN MODEL\r\n",
        "# We pass in our training data.\r\n",
        "# x_train currently has the shape (60000, 28,28), but we want to each example\r\n",
        "# to be flat so we reshape it to be (60000, 784).\r\n",
        "\r\n",
        "# 'batch_size' determines how many examples the model considers before updating\r\n",
        "# its parameters.\r\n",
        "# There are costs and benifits to both larger and smaller batch sizes.\r\n",
        "\r\n",
        "# Remember, the model considers the whole dataset 'epochs' number of times.\r\n",
        "\r\n",
        "model.fit(x_train.reshape(60000, 784), y_train, batch_size = 32, epochs = 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.7301 - accuracy: 0.7834\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2606 - accuracy: 0.9245\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2193 - accuracy: 0.9372\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2b5bdfd3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3LqdTjZsPPm",
        "outputId": "d503d672-efa6-49c8-9603-d7062bd25dd5"
      },
      "source": [
        "# To see how well the model predicts on a new data set, we evaluate\r\n",
        "# on the testing set of data\r\n",
        "\r\n",
        "model.evaluate(x_test.reshape(-1, 784), y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 975us/step - loss: 0.1982 - accuracy: 0.9434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19818450510501862, 0.9434000253677368]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "7lKLVZ9Ctk6C",
        "outputId": "366dac83-958e-4864-d710-ea59a39b47e1"
      },
      "source": [
        "# LET'S OBSERVE THE MODEL OURSELF\r\n",
        "# Change the value of 'INDEX' to check differnt example\r\n",
        "# Values between 0 and 9999 will work\r\n",
        "INDEX = 23\r\n",
        "\r\n",
        "\r\n",
        "print('Predicted:', model.predict(x_test[INDEX:INDEX+1].reshape((-1,784))), '\\n But that is kind of hard to read...')\r\n",
        "\r\n",
        "print('\\n\\n\\nPredicted:', model.predict(x_test[INDEX:INDEX+1].reshape((-1,784))).argmax(), '\\n The numpy array function \".argmax()\" returns the index with the highest value')\r\n",
        "\r\n",
        "plt.imshow(x_test[INDEX])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: [[6.46694243e-05 4.80261224e-05 5.79977524e-04 1.07200474e-04\n",
            "  1.76927529e-03 9.65427935e-01 3.07909083e-02 9.57631642e-07\n",
            "  1.17762678e-03 3.33895987e-05]] \n",
            " But that is kind of hard to read...\n",
            "\n",
            "\n",
            "\n",
            "Predicted: 5 \n",
            " The numpy array function \".argmax()\" returns the index with the highest value\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2b5a31c1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y66yaJhACdxr"
      },
      "source": [
        "Notebook and its contained images created by Joshua Zingale"
      ]
    }
  ]
}
